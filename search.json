[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Web Archive Manager (WAM)",
    "section": "",
    "text": "The Web Archive Manager (WAM) is part of the toolkit developed by the Digital Observatory to aid researchers in working with web archives.\nWAM allows you to organise, replay, and annotate your archive files (.wacz or .warc). You can also use WAM to scrape data into structured formats.\nWAM is being actively developed as a work package under the Australian Internet Observatory (AIO), funded by the Australian Research Data Commons (ARDC). Please share your feedback by emailing us at digitalobservatory@qut.edu.au."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Web Archive Manager (WAM)",
    "section": "Installation",
    "text": "Installation\n\nWindowsMacOSLinux\n\n\nWAM (Web Archive Manager)-0.0.1a\n\n\nCurrently unavailable\n\n\nCurrently unavailable"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Web Archive Manager (WAM)",
    "section": "Getting started",
    "text": "Getting started\nIn WAM, you manage web archives by projects. A default project already exists when you start the application.\n\nImporting archives\nTo import archives into your project, select File &gt; Import archives. Only files with .warc and wacz extensions are accepted.\n\nIf the archives are imported successfully, you will see them in the right table.\n\n\nReplaying archives\nTo replay an imported archive, select the archive and click Replay.\n\nOnce in the replay view, you will see a list of recorded pages. If a page is recorded multiple times, you will see all of them in this list. To view only the latest version, tick Deduplicate pages.\nTo replay a page, simply click on the page. To go back to the page list, click Back to List.\n\n\n\nAdding metadata\nIn addition to web archive’s standard metadata, You can annotate your archives by adding custom metadata.\nTo view the archive’s existing data, in the archive view, select an archive and click Edit metadata.\n\nThe standard metadata are file name, the timestamp when the archive is created, the file size. These cannot be changed or removed.\nTo add tags to an archive, select the tags row, and click Edit.\n\nIdeally, a tag should contain no spaces or other special characters, except for hyphen (“-”) and underscores (“_“). If you want to add multiple tags, separate each one with a comma and no space.\n\n\n\n\n\n\nOnce you have added or edited the tags, click Add. You might have to click the tags row again for the updates to show.\n\nAdding new custom metadata\nTo add new custom metadata, click Add metadata. You will need to specify a title for the metadata, and the value.\n\n\n\n\n\n\nNaming conventions for metadata titles\nMetadata titles are case sensitive, meaning metadataTitle and metadatatitle will be taken as two different things.\nNo spaces or special characters are allowed. The only special character you can use is @.\nStandard metadata such as file, timestamp, size, and tags are reserved, so if you try to add a metadata title using these words, they will be ignored.\nExamples of acceptable metadata titles: authorName, authorname, @authorName.\n\n\n\n\nCreating new projects\nTo create a new project, either click New in the sidebar, or Projects &gt; New in the top menu.\nYou can also add, edit or remove metadata to projects. Select a project in the project sidebar, then click Edit from the project sidebar or from the top menu. The same rules apply to naming metadata titles."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Why web archives?",
    "section": "",
    "text": "A lot of research use data sourced from the World Wide Web, and it is easy to see why. An unimaginable amount of data exist on the Web, much of is public and freely available. Web data are anything that we can find on the Web. They can be content from social media platforms, news sites, message boards, and review forums.\nOn the other hand, Web data’s ever-changing nature pose unique challenges to researchers, whose standards of research require data to be reproducible and replicable. Content on the Web can be easily modified or removed, meaning that data collected at one time might not be same if collected another time. Research that use Web data need to employ data collection methods that allow for this property of Web data."
  },
  {
    "objectID": "about.html#traditional-methods",
    "href": "about.html#traditional-methods",
    "title": "Why web archives?",
    "section": "Traditional methods",
    "text": "Traditional methods\nOne way that many researchers have used is taking screenshots of the Web page(s), using either their computer’s screenshot tool or the numerous browser extensions (e.g. GoFullPage). This is a quick and intuitive way of capturing snapshots of Web content at specific points in time. However, screenshots suffer from several major limitations. First, screenshots are usually static files (PDF or images), which do not capture the interactive elements of web pages (e.g. links, navigations, pop-ups). Second, screenshots can also be challenging to organise. For example, researchers analysing pages from different review forums may have to manually group the screenshots by forums. And lastly, web scraping of structured data cannot be done from the screenshot."
  },
  {
    "objectID": "about.html#web-archiving-as-a-data-collection-method",
    "href": "about.html#web-archiving-as-a-data-collection-method",
    "title": "Why web archives?",
    "section": "Web archiving as a data collection method",
    "text": "Web archiving as a data collection method\nWeb archiving has been used since the 90s, largely for preserving Web data in an archival format. Only recently has its potential as a research data collection technique been recognised. Web archives, for the most part, retain all features of a web page. This means that it captures all interactive elements on a page, and users can interact with the archived page as they would a live page. Web scraping can also be done on an archive.\n\nThe WARC and WACZ file formats\nArchived content are stored in WARC file format, which tends to be bundled with other files into a WACZ (Web Archive Collection Zipped) file. The WARC and WACZ file formats contain not only the web data, but also other metadata (archived time and content type) that can aid data provenance. WARC and more recently WACZ are recognised as the standard for web archiving, so these can be saved and replayed using free tools such as the Wayback Machine or ReplayWeb."
  },
  {
    "objectID": "about.html#tools-for-web-archiving",
    "href": "about.html#tools-for-web-archiving",
    "title": "Why web archives?",
    "section": "Tools for web archiving",
    "text": "Tools for web archiving\n\nWayback Machine\nThe Wayback Machine is the most well-known public archive of the Web. The Waymachine Machine began archiving the Internet in 1996, preserving all public Web content at regular intervals. This allows you to see how a web page changes over time.\nThe Wayback Machine also offers useful tools to archive web pages of your choice, provided that they are public and not hidden behind login screens or paywalls. The easiest way to do so is via the WM browser extension. All archived pages are stored publicly and can be accessed by anyone, although you can download a local copy of the archive file (WACZ) to your laptop.\n\n\nWebrecorder\nFor private pages or sensitive data that cannot be public, the Webcorder offers a suite of tools for you to make your own archives. These free Chrome browser extentions enable you to archive pages and replay them.\n\n\npywb\nResearchers with programmatic skills can use pywb for maximum customisation and automation of the archiving process."
  }
]